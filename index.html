<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S2E6XQJ50R"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-S2E6XQJ50R');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="assets/ico/favicon.png">

    <title>Chen - Personal page</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <link rel="stylesheet" href="assets/css/font-awesome.min.css">

    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>

    <script src="assets/js/jquery.min.js"></script>
    <script type="text/javascript" src="assets/js/smoothscroll.js"></script>
    <script src="assets/js/Chart.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="assets/js/html5shiv.js"></script>
      <script src="assets/js/respond.min.js"></script>
    <![endif]-->

  <body data-spy="scroll" data-offset="0" data-target="#nav">

    <div id="section-topbar">
        <div id="topbar-inner">
            <div class="container">
                <div class="row">
                    <div class="dropdown">
                        <ul id="nav" class="nav">
                            <li class="hidden"><a class="page-scroll" href="#page-top"></a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#about" title="About">About</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#news"  title="News">News</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#paper" title="Paper">Publications</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#misc"  title="Misc">Misc</a></li>
                            <li class="menu-item"><a class="page-scroll" href="Art.html"  title="Blog">Art</a></li>
                        </ul><!--/ uL#nav -->
                    </div><!-- /.dropdown -->

                    <div class="clear"></div>
                </div><!--/.row -->
            </div><!--/.container -->

            <div class="clear"></div>
        </div><!--/ #topbar-inner -->
    </div><!--/ #section-topbar -->

    <div id="headerwrap">
      <div class="container">
        <div class="row centered">
          <div class="col-lg-12">
            <h1>Chen Gao | 髙谌</h1>
            <h3>Research Scientist at Meta Reality Labs</h3><br/><br/>
            <h4><b>Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you, casting all your anxieties on him, because he cares for you. </b></h4>
            <h4><b>1 Peter 5: 6-7</b></h4>
          </div>
        </div>
      </div>
    </div>

    <section id="about" name="about"></section>
    <div id="intro">
      <div class="container">
        <div class="row">

          <!-- Avatar -->
          <div class="col-lg-3 col-md-4">
            <img class="img-responsive about-avatar" src="assets/img/chengao.jpg" alt="">
          </div>

          <!-- Text -->
          <div class="col-lg-9 col-md-8">
            <p>
              I am a research scientist at Reality Labs, Meta. My interest lies in the field of
              computational photography and 3D computer vision.
            </p>

            <p>
              I received my Ph.D. from Virginia Tech in 2022, advised by
              <a href="https://filebox.ece.vt.edu/~jbhuang/">Jia-Bin Huang</a>.
              Prior to that, I was a Master's student at the University of Michigan.
              I received my Bachelor's degree from Oregon State University.
            </p>

            <p class="about-links">
              <a href="mailto:gaochen@meta.com">Email</a> &nbsp;/&nbsp;
              <a href="Files/CV_ChenGao.pdf">CV</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=xRsWVc4AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
              <a href="https://twitter.com/gaochen315">Twitter</a> &nbsp;/&nbsp;
              <a href="https://github.com/gaochen315">Github</a>
            </p>
          </div>

        </div>
      </div>
    </div>


    <section id="news" name="news"></section>
    <div class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>NEWS</h5>
        </div>

        <div class="col-lg-10">
          <div class="news-list">

            <div class="news-row">
              <div class="news-tag">
                <paper>[2025/02]</paper>
              </div>
              <div class="news-text">
                Our paper on textured Gaussians is accepted to CVPR 2025.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <codes>[2023/06]</codes>
              </div>
              <div class="news-text">
                The <a href="https://github.com/facebookresearch/localrf">code</a> of our CVPR 2023 local RF paper is released.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <codes>[2023/06]</codes>
              </div>
              <div class="news-text">
                The <a href="https://github.com/facebookresearch/robust-dynrf">code</a> of our CVPR 2023 robust DynRF paper is released.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <activity>[2022/05]</activity>
              </div>
              <div class="news-text">
                I passed my PhD defense today!
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <intern>[2022/03]</intern>
              </div>
              <div class="news-text">
                I will be joining Meta as a research scientist.
              </div>
            </div>

          </div>
        </div>
      </div>
      <br>
      <hr>
    </div>



    <section id="paper" name="paper"></section>
        <div class="container desc">
        <div class="row">
          <div class="col-lg-2 col-lg-offset-0">
              <h5>PUBLICATION</h5>
          </div><br/><br/>

          <!-- Textured Gaussians -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://www.qinboli.com/images/content/texturedGS.mp4" type="video/mp4">
              </video>
            </div>

            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Textured Gaussians for Enhanced 3D Scene Appearance Modeling</t>
              </p>

              <p class="pub-authors">
                Brian Chao, Hung-Yu Tseng, Lorenzo Porzi, <b>Chen Gao</b>, Tuotuo Li, Qinbo Li, Ayush Saraf, Jia-Bin Huang, Johannes Kopf, Gordon Wetzstein, Changil Kim
              </p>

              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2025</b> </i>
              </p>

              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2411.18625" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://textured-gaussians.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Reflection-Aware NeRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://ra-nerf.github.io/supp/results/Ours/composite/game_room_composite.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Reflection-Aware Neural Radiance Fields</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yipeng Wang, Changil Kim, Jia-Bin Huang, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i><b>SIGGRAPH Asia 2024</b> (Conference track)</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2411.04984" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://ra-nerf.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Ambient Gaussian -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://ambientgaussian.github.io/siggraph2024/more_results/IMG_0017/merge-wo-reconstruction.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Modeling Ambient Scene Dynamics for Free-view Synthesis</t>
              </p>
              <p class="pub-authors">
                Meng-Li Shih, Jia-Bin Huang, Changil Kim, Rajvi Shah, Johannes Kopf, <b>Chen Gao</b>
              </p>
              <p class="pub-venue">
                <i><b>SIGGRAPH 2024</b> (Conference track)</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2406.09395" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://ambientgaussian.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- SpecNeRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="https://limacv.github.io/SpecNeRF_web/images/teaser.jpg" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>SpecNeRF: Gaussian Directional Encoding for Specular Reflections</t>
              </p>
              <p class="pub-authors">
                Li Ma, Vasu Agrawal, Haithem Turki, Changil Kim, <b>Chen Gao</b>, Pedro V. Sander, Michael Zollhöfer, Christian Richardt
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2024</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2312.13102" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://limacv.github.io/SpecNeRF_web/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- OmnimatteRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://omnimatte-rf.github.io/demo/demo4.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>OmnimatteRF: Robust Omnimatte with 3D Background Modeling</t>
              </p>
              <p class="pub-authors">
                Geng Lin, <b>Chen Gao</b>, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, Ayush Saraf
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE International Conference on Computer Vision <b>(ICCV) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2309.07749.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://omnimatte-rf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/OmnimatteRF" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- LocalRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://localrf.github.io/videos/forest1_ours.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Progressively Optimized Local Radiance Fields for Robust View Synthesis</t>
              </p>
              <p class="pub-authors">
                Andreas Meuleman, Yu-Lun Liu, <b>Chen Gao</b>, Jia-Bin Huang, Changil Kim, Min H. Kim, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://localrf.github.io/localrf.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://localrf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/localrf" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Robust Dynamic Radiance Fields -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://robust-dynrf.github.io/static/videos/outputvideo.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Robust Dynamic Radiance Fields</t>
              </p>
              <p class="pub-authors">
                Yu-Lun Liu, <b>Chen Gao</b>, Andreas Meuleman, Hung-Yu Tseng, Ayush Saraf,
                Changil Kim, Yung-Yu Chuang, Johannes Kopf, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2301.02239.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://robust-dynrf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/robust-dynrf" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Dynamic View Synthesis from Dynamic Monocular Video -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://filebox.ece.vt.edu/~chengao/free-view-video/teaser.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Dynamic View Synthesis from Dynamic Monocular Video</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Ayush Saraf, Johannes Kopf, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE International Conference on Computer Vision <b>(ICCV) 2021</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2105.06468.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://free-view-video.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/DynamicNeRF" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Portrait Neural Radiance Fields -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="assets/img/pnerf.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Portrait Neural Radiance Fields from a Single Image</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yichang Shih, Wei-Sheng Lai, Chia-Kai Liang, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>arXiv preprint</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2012.05903.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://portrait-nerf.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Flow-edge Guided Video Completion -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://gaochen315.github.io/FGVC/ECCV2020/teaser.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Flow-edge Guided Video Completion</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Ayush Saraf, Jia-Bin Huang, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2009.01835.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/FGVC/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/FGVC" target="_blank">Code</a>]
                &nbsp;
                [<a href="https://colab.research.google.com/drive/1pb6FjWdwq_q445rG2NP0dubw7LKNUkqc?usp=sharing" target="_blank">Google Colab</a>]
              </p>
            </div>
          </div>

          <!-- DRG -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="assets/img/DRG.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>DRG: Dual Relation Graph for Human-Object Interaction Detection</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Jiarui Xu, Yuliang Zou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2008.11714.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="http://chengao.vision/DRG/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/DRG" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- NAS-DIP -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/NAS-DIP.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>NAS-DIP: Learning Deep Image Prior with Neural Architecture Search</t>
              </p>
              <p class="pub-authors">
                Yun-Chun Chen*, <b>Chen Gao*</b>, Esther Robb, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2008.11713.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://yunchunchen.github.io/NAS-DIP/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/YunChunChen/NAS-DIP-pytorch" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- SDN -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/SDN.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition</t>
              </p>
              <p class="pub-authors">
                Jinwoo Choi, <b>Chen Gao</b>, Joseph Messou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of Neural Information Processing Systems <b>(NeurIPS) 2019</b></i>
              </p>
              <p class="pub-links">
                [<a href="http://papers.nips.cc/paper/8372-why-cant-i-dance-in-the-mall-learning-to-mitigate-scene-bias-in-action-recognition.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="http://chengao.vision/SDN/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/SDN" target="_blank">Code</a>]
                &nbsp;
                [<a href="Files/Debaising_Poster.pdf" target="_blank">Poster</a>]
              </p>
            </div>
          </div>

          <!-- iCAN -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/HOI.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yuliang Zou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of The British Machine Vision Conference <b>(BMVC) 2018</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1808.10437" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/iCAN/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/iCAN" target="_blank">Code</a>]
                &nbsp;
                [<a href="Files/iCAN_Poster.pdf" target="_blank">Poster</a>]
              </p>
            </div>
          </div>

          <!-- pRPCA -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/pRPCA.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Panoramic Robust PCA for Foreground-Background Separation on Noisy, Free-Motion Camera Video</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao*</b>, Brian E. Moore*, Raj Rao Nadakuditi
              </p>
              <p class="pub-venue">
                <i>IEEE Transactions on Computational Imaging <b>(TCI) 2019</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1712.06229" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/pRPCA/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/panoramicRPCA" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Augmented RPCA -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/RPCA.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <t>Augmented Robust PCA For Foreground-Background Separation on Noisy, Moving Camera Video</t>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Brian E. Moore, Raj Rao Nadakuditi
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Global Conference on Signal and Information Processing <b>(GlobalSIP) 2017 (Oral)</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1709.09328" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/pRPCA/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/panoramicRPCA" target="_blank">Code</a>]
                &nbsp;
                [<a href="https://drive.google.com/file/d/1lLk_qa3o6uR22ZM3vTm2hBJ-hH_Tkoin/view?usp=sharing" target="_blank">Slides</a>]
              </p>
            </div>
          </div>

        </div>
        <br>
        <hr>
    </div><!--/.container -->


    <!--EDUCATION DESCRIPTION -->
    <div class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>EDUCATION</h5>
        </div>

        <div class="col-lg-10">
          <div class="edu-list">

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/vt.png" alt="">
              <p class="text-center">
                Virginia Tech <br/>
                Doctor of Philosophy
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/umich.png" alt="">
              <p class="text-center">
                University of Michigan <br/>
                Master of Science
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/osu_.png" alt="">
              <p class="text-center">
                Oregon State University <br/>
                Bachelor of Science
              </p>
            </div>

          </div>
        </div>
      </div>
      <br/>
      <hr>
    </div>


    <div class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>INDUSTRY</h5>
        </div>

        <div class="col-lg-10">
          <div class="edu-list">

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/Meta.png" alt="">
              <p class="text-center">
                Research Scientist <br/>
                2022 - Present
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/google.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2021
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/google.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2020
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/facebook.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2019
              </p>
            </div>

          </div>
        </div>
      </div>
      <br/>
      <hr>
    </div>


    <!--AWARDS DESCRIPTION -->
    <!-- <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>ACTIVITIES</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Conference Reviewer</t><br/>
                        SIGGRAPH 2021-2022, BMVC 2019-2020, NeurIPS 2020-2021, CVPR 2020-2022, ACCV 2020, WACV 2020-2021 <br/>
                    </p>
                    <p><t>Journal Reviewer</t><br/>
                        TPAMI, TIP, IJCV <br/>
                    </p>
                </div>
        </div>
        <br>
        <hr>
    </div> -->

    <!-- <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>COURSES</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Virginia Tech</t><br/>
                        STAT5444 - Bayesian Statistics <br/>
                        CS6804 - Graph Machine Learning <br/>
                        CS6804 - Causal Reasoning <br/>
                        ECE5454 - Optimization Techniques <br/>
                        CS5984 - Natural Language Processing <br/>
                    </p>
                    <p><t>University of Michigan</t><br/>
                        EECS442 - Computer Vision <br/>
                        EECS501 - Probability and Random Processes <br/>
                        EECS551 - Matrix Methods <br/>
                        EECS542 - Advanced Topics in Computer Vision <br/>
                        EECS545 - Machine Learning <br/>
                        EECS587 - Parallel Computing <br/>
                        EECS592 - Advanced Artificial Intelligence <br/>
                        EECS598 - Random Matrix Theory <br/>
                    </p>
                </div>
        </div>
        <br>
        <hr>
    </div> -->


    <!-- <section id="teaching" name="teaching"></section>
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>TEACHING</h5>
                </div>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-2">
                            <pp class='text-left'> Teaching Assistant </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            ECE 5554 / ECE 4554 (Computer Vision), Fall 2018 [<a href="https://filebox.ece.vt.edu/~jbhuang/teaching/ece5554-4554/fa18/index.html">Link</a>] &nbsp;&nbsp; [<a href="Files/Chen_Tutorial_on_Linear_Algebra_and_MATLAB.zip">Tutorial</a>]
                        </pp> </div>
                    </div>
                </div>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-2">
                            <pp class='text-left'> Teaching Assistant </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            ECE 5424 / CS 5824 (Advanced Machine Learning), Spring 2019 [<a href="https://filebox.ece.vt.edu/~jbhuang/teaching/ECE5424-CS5824/sp19/index.html">Link</a>] [<a href="Files/Lec10.pptx">Lecture on Neural Network</a>]

                        </pp> </div>
                    </div>
                </div>
        </div>
        <br>
        <hr>
    </div> -->

    <section id="misc" name="misc"></section>
    <div class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>MISC</h5>
        </div>

        <div class="col-lg-10 misc-content">

          <div class="misc-item">
            <p><t>Road Trip</t></p>
            <p>
              I enjoy road-trip as it's a great way to experience local customs.
              The spectacular landscape reminds me of how great our Creator is.
              One of my dreams is to visit all the 59 national parks in the US.
              I have visited 22 national parks already and am looking forward to my next journey.
              Here is a list of the national parks I've visited
            </p>

            <ul class="misc-list">
              <li>Arches - Utah</li>
              <li>Bryce Canyon - Utah (Favourite!)</li>
              <li>Canyonlands - Utah</li>
              <li>Capitol Reef - Utah</li>
              <li>Crater Lake - Oregon</li>
              <li>Everglades - Florida</li>
              <li>Glacier National Park - Montana</li>
              <li>Grand Canyon - Arizona</li>
              <li>Grand Teton - Wyoming</li>
              <li>Great Sand Dunes - Colorado</li>
              <li>Great Smoky Mountains - North Carolina, Tennessee</li>
              <li>Joshua Tree - California</li>
              <li>Kings Canyon - California</li>
              <li>Mesa Verde - Colorado</li>
              <li>Mount Rainier - Washington</li>
              <li>North Cascades - Washington</li>
              <li>Olympic - Washington</li>
              <li>Sequoia - California</li>
              <li>Shenandoah - Virginia</li>
              <li>Yellowstone - Wyoming, Montana, Idaho</li>
              <li>Yosemite - California</li>
              <li>Zion - Utah</li>
            </ul>
          </div>

          <div class="misc-item">
            <p><t>Painting</t></p>
            <p>
              I spent 6 years learning figure sketch,
              <a href="https://en.wikipedia.org/wiki/Chinese_painting" target="_blank" rel="noopener noreferrer">traditional Chinese painting</a>,
              and <a href="https://en.wikipedia.org/wiki/Gongbi" target="_blank" rel="noopener noreferrer">Gongbi</a>,
              specialized in <a href="https://en.wikipedia.org/wiki/Bird-and-flower_painting" target="_blank" rel="noopener noreferrer">Bird-and-flower painting</a>.
              Through painting, I find inner peace.
              These days I enjoy drawing some anime characters for fun.
              Check <a href="Art.html" target="_blank" rel="noopener noreferrer">them</a> out.
            </p>
          </div>

          <div class="misc-item">
            <p><t>Activities</t></p>
            <p>
              I regularly engage in hiking, paddleboarding, and snowboarding.
              If you're in Seattle and enjoy outdoor activities, feel free to contact me.
            </p>
          </div>

          <div class="misc-item">
            <p><t>Big fan of Rubik's Cube</t></p>
            <p>
              4x4x4 <br/>
              5x5x5
            </p>
          </div>

          <div class="misc-item">
            <p><t>Games</t></p>
            <p>
              I'll call the following games Masterpiece because they change my perspective somehow.
            </p>
            <ul class="misc-list">
              <li>AIR - VisualArt's</li>
              <li>Portal - Valve</li>
              <li>To the moon - Freebird Games</li>
            </ul>
          </div>

          <!-- <div class="misc-item">
            <p><t>Music</t></p>
            <ul class="misc-list">
              <li>The Police - <a href="https://www.youtube.com/watch?v=OMOGaugKpzs&ab_channel=ThePoliceVEVO" target="_blank" rel="noopener noreferrer">Every Breath You Take</a></li>
              <li>Radiohead - <a href="https://www.youtube.com/watch?v=u5CVsCnxyXg&ab_channel=Radiohead" target="_blank" rel="noopener noreferrer">No Surprises</a></li>
              <li>Radiohead - <a href="https://www.youtube.com/watch?v=t_ENqnpHvD8&ab_channel=TheOrlandometal" target="_blank" rel="noopener noreferrer">Creep (Korn Cover)</a></li>
              <li>Coldplay - <a href="https://www.youtube.com/watch?v=k4V3Mo61fJM&ab_channel=Coldplay" target="_blank" rel="noopener noreferrer">Fix You</a></li>
              <li>宋冬野 - <a href="https://www.youtube.com/watch?v=FiJHoPrS4Y4&ab_channel=%E9%84%92%E5%85%81%E6%9D%B0Gariber" target="_blank" rel="noopener noreferrer">莉莉安</a></li>
              <li>李志 - <a href="https://www.youtube.com/watch?v=K2QE-FRAP0o&ab_channel=%E6%9D%8E%E5%BF%97Lizhi" target="_blank" rel="noopener noreferrer">热河路</a></li>
            </ul>
          </div> -->

          <div class="misc-item">
            <p><t>The Mighty</t></p>
            <p>
              Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you,
              casting all your anxieties on him, because he cares for you.
            </p>
            <p style="text-align:right;">
              1 Peter 5: 6-7
            </p>
          </div>

        </div>
      </div>
    </div>


    <section id="contact" name="contact"></section>

    <div id="footwrap">
      <div class="container">
        <div class="row">

          <div class="col-lg-2 col-lg-offset-0">
            <h5>CONTACT</h5>
          </div>

          <div class="col-lg-5">
            <p>
              <t>Email</t><br/>
              gaochen@meta.com
            </p>
          </div>

          <div class="col-lg-3 col-lg-offset-2">
            <p><sm>SOCIAL LINKS</sm></p>
            <p class="footer-social">
              <a href="https://www.facebook.com/ChenGao315"><i class="icon-facebook"></i></a>
              <a href="https://www.linkedin.com/in/chen-gao-729649a0/"><i class="icon-linkedin"></i></a>
              <a href="https://twitter.com/gaochen315"><i class="icon-twitter"></i></a>
            </p>
            <p class="footer-counter">
              <a href="http://www.easycounter.com/">
                <img alt="HTML Counter" src="http://www.easycounter.com/counter.php?gaochen315" border="0">
              </a>
            </p>
          </div>

        </div>
      </div>
    </div>


     <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.js"></script>
  </body>
</html>
