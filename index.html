<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S2E6XQJ50R"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-S2E6XQJ50R');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="assets/ico/favicon.png">

    <title>Chen - Personal page</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <link rel="stylesheet" href="assets/css/font-awesome.min.css">

    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>

    <script src="assets/js/jquery.min.js"></script>
    <script type="text/javascript" src="assets/js/smoothscroll.js"></script>
    <script src="assets/js/Chart.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="assets/js/html5shiv.js"></script>
      <script src="assets/js/respond.min.js"></script>
    <![endif]-->

  <body data-spy="scroll" data-offset="0" data-target="#nav">

    <div id="section-topbar">
        <div id="topbar-inner">
            <div class="container">
                <div class="row">
                    <div class="dropdown">
                        <ul id="nav" class="nav">
                            <li class="hidden"><a class="page-scroll" href="#page-top"></a></li>
                            <li class="menu-item"><a class="page-scroll" href="#about" title="About">About</a></li>
                            <li class="menu-item"><a class="page-scroll" href="#news"  title="News">News</a></li>
                            <li class="menu-item"><a class="page-scroll" href="#paper" title="Paper">Publications</a></li>
                            <li class="menu-item"><a class="page-scroll" href="#misc"  title="Misc">Misc</a></li>
                            <li class="menu-item"><a class="page-scroll" href="Art.html"  title="Blog">Art</a></li>
                        </ul><!--/ uL#nav -->
                    </div><!-- /.dropdown -->

                    <div class="clear"></div>
                </div><!--/.row -->
            </div><!--/.container -->

            <div class="clear"></div>
        </div><!--/ #topbar-inner -->
    </div><!--/ #section-topbar -->

    <div id="headerwrap">
        <div class="container">
            <div class="row centered">
                <div class="col-lg-12">
                    <h1>Chen Gao | 髙谌</h1>
                    <h3>Research scientist | gaochen@meta.com</h3><br/><br/>
                    <h4><b>Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you, casting all your anxieties on him, because he cares for you. </b></h4>
                    <h4><b>1 Peter 5: 6-7</b></h4>
                </div><!--/.col-lg-12 -->
            </div><!--/.row -->
        </div><!--/.container -->
    </div><!--/.#headerwrap -->


    <section id="about" name="about"></section>
    <div id="intro">
        <div class="container">
            <div class="row">

                <div class="col-lg-2 col-lg-offset-0">
                    <h5>ABOUT ME</h5>
                </div>
                <div class="col-lg-7">
                    <p>I am a research scientist at Reality Labs, Meta. My interest lies in the field of computational photography and 3D computer vision.</p>
                    <p>I received my Ph.D. from Virginia Tech in 2022, advised by <a href="https://filebox.ece.vt.edu/~jbhuang/">Jia-Bin Huang</a>. Prior to that, I was a Master's student at the University of Michigan. I received my Bachelor's degree from Oregon State University.</p>
                    <p>Feel free to drop me an email if you're interested in collaborating with me and our team.</p>
                </div>
                <div class="col-lg-2">
                    <p><img class="img-responsive" src="assets/img/chengao.jpg" alt=""></p><br/>
                </div>

                <!-- <div class="col-lg-2 col-lg-offset-0">
                    <p>
                        <a href="https://scholar.google.com/citations?user=xRsWVc4AAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><i class="icon-google-plus"></i></a>
                        <a href="https://github.com/gaochen315" target="_blank" rel="noopener noreferrer"><i class="icon-github"></i></a>
                        <a href="https://www.facebook.com/ChenGao315" target="_blank" rel="noopener noreferrer"><i class="icon-facebook"></i></a>
                        <a href="https://www.linkedin.com/in/chen-gao-729649a0/" target="_blank" rel="noopener noreferrer"><i class="icon-linkedin"></i></a>
                        <a href="https://twitter.com/gaochen315" target="_blank" rel="noopener noreferrer"><i class="icon-twitter"></i></a>
                    </p>
                </div> -->
                <div class="col-lg-7">
                    <!-- <p>Please find my CV <a href="Files/CV_ChenGao.pdf" target="_blank" rel="noopener noreferrer">here</a> (last updated on Oct 2023).</p> -->
                    <p>
                    <a href="mailto:gaochen@meta.com">Email</a> &nbsp;/&nbsp;
                    <a href="Files/CV_ChenGao.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=xRsWVc4AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/gaochen315">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/gaochen315">Github</a>
                  </p>
                </div>


            </div>
        </div>
    </div>


    <section id="news" name="news"></section>
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>NEWS</h5>
                </div>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-1">
                            <codes class='text-left'> [2023/09] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/facebookresearch/OmnimatteRF">code</a> of our ICCV 2023 Omnimatte RF paper is released! Check the <a href="https://omnimatte-rf.github.io/">Project page</a> for details.
                        </black> </div>
                        <!-- <div class="col-sm-1">
                            <paper class='text-left'> [2023/07] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                          Our paper on robust Omnimatte, is accepted to ICCV 2023.
                        </black> </div> -->
                        <div class="col-sm-1">
                            <codes class='text-left'> [2023/06] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/facebookresearch/localrf">code</a> of our CVPR 2023 local RF paper is released! Check the <a href="https://localrf.github.io/">Project page</a> for details.
                        </black> </div>
                        <div class="col-sm-1">
                            <codes class='text-left'> [2023/06] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/facebookresearch/robust-dynrf">code</a> of our CVPR 2023 robust DynRF paper is released! Check the <a href="https://robust-dynrf.github.io/">Project page</a> for details.
                        </black> </div>
                        <div class="col-sm-1">
                            <activity class='text-left'> [2022/05] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I passed my PhD defense today!
                        </black> </div>
                        <div class="col-sm-1">
                            <intern class='text-left'> [2022/03] </intern>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be joining Meta as a research scientist.
                        </black> </div>
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2021/12] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/gaochen315/DynamicNeRF">code</a> of our ICCV 2021 dynamic view synthesis paper is released! Check the <a href="https://free-view-video.github.io/">Project page</a> for details.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2021/10] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I am selected to participate in the ICCV 2021 Doctoral Consortium and my mentor is <a href="https://www.smseitz.com/">Prof. Steve Seitz</a>.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <paper class='text-left'> [2021/07] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                          Our paper on dynamic view synthesis, is accepted to ICCV 2021.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2021/05] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I passed my Prelim today!
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <intern class='text-left'> [2021/01] </intern>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be a research intern at Google VisCam this summer, under the guidance of <a href="https://research.google/people/107089/">Dr. Mike Krainin</a> and <a href="http://people.csail.mit.edu/mrub/">Dr. Miki Rubinstein</a>.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <intern class='text-left'> [2020/10] </intern>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I am seeking 2021 summer intern opportunity.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2020/08] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/vt-vl-lab/FGVC">code</a> of our ECCV 2020 video completion paper is up!
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2020/08] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="http://chengao.vision/FGVC/">Project page</a> of our ECCV 2020 video completion paper is up.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2020/08] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/vt-vl-lab/DRG">code</a> of our ECCV 2020 HOI detection paper is released! Check the <a href="http://chengao.vision/DRG/">Project page</a> for details.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2020/08] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/YunChunChen/NAS-DIP-pytorch">code</a> of our ECCV 2020 NAS-DIP paper is released! Check the <a href="https://yunchunchen.github.io/NAS-DIP/">Project page</a> for details.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <paper class='text-left'> [2020/07] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                          Three papers are accepted to ECCV 2020.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2020/06] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be an official reviewer for BMVC 2020, WACV 2021 and ACCV 2020.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2020/03] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I passed my Ph.D. qualifying exam today.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2020/03] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be an official reviewer for NeurIPS 2020.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <intern class='text-left'> [2020/02] </intern>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be a research intern at Google this summer, under the guidance of <a href="https://people.csail.mit.edu/yichangshih/">Dr. YiChang Shih</a>.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <codes class='text-left'> [2019/12] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/vt-vl-lab/SDN">code</a> of our NeurIPS2019 paper is released! Check the <a href="http://chengao.vision/SDN/">Project page</a> for details.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2019/11] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be an official reviewer for CVPR 2020.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <activity class='text-left'> [2019/10] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            Thanks NeuraIPS for awarding me with a NeuraIPS 2019 travel grant.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <paper class='text-left'> [2019/09] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                          Our paper on action debaising, is accepted to NeurIPS2019. See you at Vancouver, Canada.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <intern class='text-left'> [2019/02] </intern>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will be a research intern at Facebook Seattle this summer, under the guidance of <a href="http://johanneskopf.de/">Dr. Johannes Kopf</a>.
                        </black> </div> -->
                        <!-- <div class="col-sm-1">
                            <paper class='text-left'> [Paper] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            Our paper on foreground-background separation, is accepted to IEEE TCI.
                        </black> </div>

                        <div class="col-sm-1">
                            <codes class='text-left'> [Code] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/gaochen315/panoramicRPCA">code</a> of our GlobalSIP2017 paper is released! Check the <a href="https://gaochen315.github.io/pRPCA/">Project page</a> for details.
                        </black> </div>
                      	<div class="col-sm-1">
                            <codes class='text-left'> [Code] </codes>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            The <a href="https://github.com/vt-vl-lab/iCAN">code</a> of our BMVC2018 paper is released! Check the <a href="https://gaochen315.github.io/iCAN/">Project page</a> for details.
                        </black> </div>
                        <div class="col-sm-1">
                            <paper class='text-left'> [Paper] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                        	Our paper on HOI detection, is accepted to BMVC 2018. See you at Newcastle, UK.
                        </black> </div> -->
<!--                         <div class="col-sm-1">
                            <activity class='text-left'> [Activity] </activity>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            I will join Prof. Jia-Bin Huang's group as a PhD student starting in August.
                        </black> </div> -->
<!--                         <div class="col-sm-1">
                            <pp class='text-left'> 2017/12 </pp>
                        </div>
                        <div class="col-sm-11"> <pp class='text-left'>
                            One paper submitted to IEEE Transactions on Computational Imaging.
                        </pp> </div>
                        <div class="col-sm-1">
                            <pp class='text-left'> 2017/08 </pp>
                        </div>
                        <div class="col-sm-11">
                            <pp class='text-left'>
                            I received Rackham International Travel Grant from University of Michigan.
                        </pp> </div> -->
<!--                         <div class="col-sm-1">
                            <paper class='text-left'> [Paper] </paper>
                        </div>
                        <div class="col-sm-11"> <black class='text-left'>
                            One paper on foreground-background separation and denoising accepted to GlobalSIP 2017.
                        </black> </div> -->
    <!--                     <div class="col-sm-2">
                            <pp class='text-left'> June. 20, 2017 </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            I joined the ECE department at Virgina Tech as a research assistant, under the supervision of Prof. Jia-Bin Huang.
                        </pp> </div>
                        <div class="col-sm-2">
                            <pp class="text-left"> Apr. 29, 2017 </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            I graduate from University of Michigan with a Masters' degree today.
                        </pp> </div> -->
                    </div>
                </div>
        </div><!--/.row -->
        <br>
        <hr>
    </div><!--/.container -->


    <section id="paper" name="paper"></section>
        <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>PUBLICATION</h5>
                </div><br/><br/>

                <div class="col-lg-3">
                </div>
                <div class="col-lg-8">
                    <p><t>Reflection-Aware Neural Radiance Fields</t><br/>
                        <b>Chen Gao</b>, Yipeng Wang, Changil Kim, Jia-Bin Huang, Johannes Kopf<br/>
                        <i><b>SIGGRAPH Asia 2024</b> (Conference track)</i> <br/>
                    </p><br/><br/>
                </div>


                <div class="col-lg-3">
                    <p>
                      <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://ambientgaussian.github.io/siggraph2024/more_results/IMG_0017/merge-wo-reconstruction.mp4">
                      <source src="https://ambientgaussian.github.io/siggraph2024/more_results/IMG_0017/merge-wo-reconstruction.mp4" type="video/mp4">
                      </video>
                    </p>
                  </div>
                <div class="col-lg-8">
                    <p><t>Modeling Ambient Scene Dynamics for Free-view Synthesis</t><br/>
                        Meng-Li Shih, Jia-Bin Huang, Changil Kim, Rajvi Shah, Johannes Kopf, <b>Chen Gao</b><br/>
                        <i><b>SIGGRAPH 2024</b> (Conference track)</i> <br/>
                        [<a href="https://arxiv.org/pdf/2406.09395" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]   &nbsp;&nbsp; [<a href="https://ambientgaussian.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="#" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                    <p>
                      <img class="img-responsive" src="https://limacv.github.io/SpecNeRF_web/images/teaser.jpg" alt="">
                    </p>
                  </div>
                <div class="col-lg-8">
                    <p><t>SpecNeRF: Gaussian Directional Encoding for Specular Reflections</t><br/>
                        Li Ma, Vasu Agrawal, Haithem Turki, Changil Kim, <b>Chen Gao</b>, Pedro V. Sander, Michael Zollhöfer, Christian Richardt<br/>
                        <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2024</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2312.13102" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://limacv.github.io/SpecNeRF_web/" target="_blank" rel="noopener noreferrer">Project page</a>]<br/>
                    </p><br/>
                </div>


                <div class="col-lg-3">
                    <p>
                      <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://omnimatte-rf.github.io/demo/demo4.mp4">
                      <source src="https://omnimatte-rf.github.io/demo/demo4.mp4" type="video/mp4">
                      </video>
                    </p>
                  </div>
                <div class="col-lg-8">
                    <p><t>OmnimatteRF: Robust Omnimatte with 3D Background Modeling</t><br/>
                        Geng Lin, <b>Chen Gao</b>, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, and Ayush Saraf<br/>
                        <i>Proceedings of International Conference on Computer Vision <b>(ICCV) 2023</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2309.07749.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://omnimatte-rf.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/facebookresearch/OmnimatteRF" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://localrf.github.io/videos/forest1_ours.mp4">
                    <source src="https://localrf.github.io/videos/forest1_ours.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>Progressively Optimized Local Radiance Fields for Robust View Synthesis</t><br/>
                        Andreas Meuleman, Yu-Lun Liu, <b>Chen Gao</b>, Jia-Bin Huang, Changil Kim, Min H. Kim, Johannes Kopf<br/>
                        <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b> </i> <br/>
                        [<a href="https://localrf.github.io/localrf.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://localrf.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/facebookresearch/localrf" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://robust-dynrf.github.io/static/videos/outputvideo.mp4">
                    <source src="https://robust-dynrf.github.io/static/videos/outputvideo.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>Robust Dynamic Radiance Fields</t><br/>
                        Yu-Lun Liu, <b>Chen Gao</b>, Andreas Meuleman, Hung-Yu Tseng, Ayush Saraf, Changil Kim, Yung-Yu Chuang, Johannes Kopf, Jia-Bin Huang<br/>
                        <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2301.02239.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://robust-dynrf.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/facebookresearch/robust-dynrf" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://filebox.ece.vt.edu/~chengao/free-view-video/teaser.mp4">
                    <source src="https://filebox.ece.vt.edu/~chengao/free-view-video/teaser.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>Dynamic View Synthesis from Dynamic Monocular Video</t><br/>
                        <b>Chen Gao</b>, Ayush Saraf, Johannes Kopf, Jia-Bin Huang<br/>
                        <i>Proceedings of IEEE International Conference on Computer Vision <b>(ICCV) 2021</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2105.06468.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://free-view-video.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/gaochen315/DynamicNeRF" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="assets/img/pnerf.mp4">
                    <source src="assets/img/pnerf.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>Portrait Neural Radiance Fields from a Single Image</t><br/>
                        <b>Chen Gao</b>, Yichang Shih, Wei-Sheng Lai, Chia-Kai Liang, Jia-Bin Huang<br/>
                        <i>arXiv preprint</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2012.05903.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://portrait-nerf.github.io/" target="_blank" rel="noopener noreferrer">Project page</a>]<br/>
                    </p><br/><br/><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="https://gaochen315.github.io/FGVC/ECCV2020/teaser.mp4">
                    <source src="https://gaochen315.github.io/FGVC/ECCV2020/teaser.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>Flow-edge Guided Video Completion</t><br/>
                        <b>Chen Gao</b>, Ayush Saraf, Jia-Bin Huang, Johannes Kopf<br/>
                        <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2009.01835.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://gaochen315.github.io/FGVC/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/vt-vl-lab/FGVC" target="_blank" rel="noopener noreferrer">Code</a>]  &nbsp;&nbsp; [<a href="https://colab.research.google.com/drive/1pb6FjWdwq_q445rG2NP0dubw7LKNUkqc?usp=sharing" target="_blank" rel="noopener noreferrer">Google Colab</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                  <p>
                    <video id="vid" class="img-responsive" muted="muted" controls= "autoPlay" onended="this.currentTime = 0; this.play();" autoplay="" src="assets/img/DRG.mp4">
                    <source src="assets/img/DRG.mp4" type="video/mp4">
                    </video>
                  </p>
                </div>
                <div class="col-lg-8">
                    <p><t>DRG: Dual Relation Graph for Human-Object Interaction Detection</t><br/>
                        <b>Chen Gao</b>, Jiarui Xu, Yuliang Zou, Jia-Bin Huang<br/>
                        <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2008.11714.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="http://chengao.vision/DRG/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/vt-vl-lab/DRG" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                    <p><img class="img-responsive" src="assets/img/NAS-DIP.gif" alt=""></p>
                </div>
                <div class="col-lg-8">
                    <p><t>NAS-DIP: Learning Deep Image Prior with Neural Architecture Search</t><br/>
                        Yun-Chun Chen*, <b>Chen Gao*</b>, Esther Robb, Jia-Bin Huang<br/>
                        <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b> </i> <br/>
                        [<a href="https://arxiv.org/pdf/2008.11713.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://yunchunchen.github.io/NAS-DIP/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/YunChunChen/NAS-DIP-pytorch" target="_blank" rel="noopener noreferrer">Code</a>]<br/>
                    </p><br/><br/>
                </div>

                <div class="col-lg-3">
                    <p><img class="img-responsive" src="assets/img/SDN.gif" alt=""></p>
                </div>
                <div class="col-lg-8">
                    <p><t>Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition</t><br/>
                        Jinwoo Choi, <b>Chen Gao</b>, Joseph Messou, Jia-Bin Huang<br/>
                        <i>Proceedings of Neural Information Processing Systems <b>(NeurIPS) 2019</b> </i> <br/>
                        [<a href="http://papers.nips.cc/paper/8372-why-cant-i-dance-in-the-mall-learning-to-mitigate-scene-bias-in-action-recognition.pdf" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="http://chengao.vision/SDN/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/vt-vl-lab/SDN" target="_blank" rel="noopener noreferrer">Code</a>]   &nbsp;&nbsp; [<a href="Files/Debaising_Poster.pdf" target="_blank" rel="noopener noreferrer">Poster</a>]<br/>
                    </p><br/><br/>
                </div>
                <div class="col-lg-3">
                    <p><img class="img-responsive" src="assets/img/HOI.gif" alt=""></p>
                </div>
                <div class="col-lg-8">
                    <p><t>iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection</t><br/>
                        <b>Chen Gao</b>, Yuliang Zou, Jia-Bin Huang<br/>
                        <i>Proceedings of The British Machine Vision Conference <b>(BMVC) 2018</b> </i> <br/>
                        [<a href="https://arxiv.org/abs/1808.10437" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://gaochen315.github.io/iCAN/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/vt-vl-lab/iCAN" target="_blank" rel="noopener noreferrer">Code</a>]   &nbsp;&nbsp; [<a href="Files/iCAN_Poster.pdf" target="_blank" rel="noopener noreferrer">Poster</a>]<br/>
                    </p><br/><br/>
                </div>
                <div class="col-lg-3">
                    <p><img class="img-responsive" src="assets/img/pRPCA.gif" alt=""></p>
                </div>
                <div class="col-lg-8">
                    <p><t>Panoramic Robust PCA for Foreground-Background Separation on Noisy, Free-Motion Camera Video</t><br/>
                        <b>Chen Gao*</b>, Brian E. Moore*, Raj Rao Nadakuditi<br/>
                        <i>IEEE Transactions on Computational Imaging <b>(TCI) 2019</b></i> <br/>
                        [<a href="https://arxiv.org/abs/1712.06229">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://gaochen315.github.io/pRPCA/">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/gaochen315/panoramicRPCA">Code</a>] <br/>
                    </p><br/><br/><br/><br/>
                </div>
                <div class="col-lg-3">
                    <p><img class="img-responsive" src="assets/img/RPCA.gif" alt=""></p>
                </div>
                <div class="col-lg-8">
                    <p><t>Augmented Robust PCA For Foreground-Background Separation on Noisy, Moving Camera Video</t><br/>
                        <b>Chen Gao</b>, Brian E. Moore, Raj Rao Nadakuditi<br/>
                        <i>Proceedings of IEEE Global Conference on Signal and Information Processing <b>(GlobalSIP) 2017 (Oral)</b></i> <br/>
                        [<a href="https://arxiv.org/abs/1709.09328" target="_blank" rel="noopener noreferrer">Paper (PDF)</a>]  &nbsp;&nbsp; [<a href="https://gaochen315.github.io/pRPCA/" target="_blank" rel="noopener noreferrer">Project page</a>]  &nbsp;&nbsp; [<a href="https://github.com/gaochen315/panoramicRPCA" target="_blank" rel="noopener noreferrer">Code</a>] &nbsp;&nbsp; [<a href="https://drive.google.com/file/d/1lLk_qa3o6uR22ZM3vTm2hBJ-hH_Tkoin/view?usp=sharing" target="_blank" rel="noopener noreferrer">Slides(video demo)</a>]<br/>
                    </p>
                </div>
        </div>
        <br>
        <hr>
    </div><!--/.container -->


    <!--EDUCATION DESCRIPTION -->
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>EDUCATION</h5>
                </div><br/><br/>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-3 col-sm-offset-1">
                            <p><img class="img-responsive" src="assets/img/vt.png" alt=""></p>
                            <p class="text-center">Virginia Tech <br/> Doctor of Philosophy</p>
                        </div>
                        <div class="col-sm-3 col-sm-offset-1">
                            <p><img class="img-responsive" src="assets/img/umich.png" alt=""></p>
                            <p class="text-center">University of Michigan <br/> Master of Science</p>
                        </div>
                        <div class="col-sm-3 col-sm-offset-1">
                            <p><img class="img-responsive" src="assets/img/osu_.png" alt=""></p>
                            <p class="text-center">Oregon State University <br/> Bachelor of Science</p>
                        </div>
                    </div>
                </div>
        </div><!--/.row -->
        <br/>
        <hr>
    </div><!--/.container -->


    <!--INDUSTRY DESCRIPTION -->
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>INDUSTRY</h5>
                </div><br/><br/>
                <div class="col-lg-10">
                    <div class="row">
                      <div class="col-sm-3 col-sm-offset-1">
                          <p><img class="img-responsive" src="assets/img/google.png" alt=""></p>
                          <p class="text-center">Research Intern <br/> Summer 2021</p>
                      </div>
                      <div class="col-sm-3 col-sm-offset-1">
                          <p><img class="img-responsive" src="assets/img/google.png" alt=""></p>
                          <p class="text-center">Research Intern <br/> Summer 2020</p>
                      </div>
                      <div class="col-sm-3 col-sm-offset-1">
                          <p><img class="img-responsive" src="assets/img/facebook.png" alt=""></p>
                          <p class="text-center">Research Intern <br/> Summer 2019</p>
                      </div>
                    </div>
                </div>
        </div><!--/.row -->
        <br/>
        <hr>
    </div><!--/.container -->


    <!--AWARDS DESCRIPTION -->
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>ACTIVITIES</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Conference Reviewer</t><br/>
                        SIGGRAPH 2021-2022, BMVC 2019-2020, NeurIPS 2020-2021, CVPR 2020-2022, ACCV 2020, WACV 2020-2021 <br/>
                    </p>
                    <p><t>Journal Reviewer</t><br/>
                        TPAMI, TIP, IJCV <br/>
                    </p>
                </div>
        </div><!--/.row -->
        <br>
        <hr>
    </div><!--/.container -->

    <!-- <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>COURSES</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Virginia Tech</t><br/>
                        STAT5444 - Bayesian Statistics <br/>
                        CS6804 - Graph Machine Learning <br/>
                        CS6804 - Causal Reasoning <br/>
                        ECE5454 - Optimization Techniques <br/>
                        CS5984 - Natural Language Processing <br/>
                    </p>
                    <p><t>University of Michigan</t><br/>
                        EECS442 - Computer Vision <br/>
                        EECS501 - Probability and Random Processes <br/>
                        EECS551 - Matrix Methods <br/>
                        EECS542 - Advanced Topics in Computer Vision <br/>
                        EECS545 - Machine Learning <br/>
                        EECS587 - Parallel Computing <br/>
                        EECS592 - Advanced Artificial Intelligence <br/>
                        EECS598 - Random Matrix Theory <br/>
                    </p>
                </div>
        </div>
        <br>
        <hr>
    </div> -->


    <!-- <section id="teaching" name="teaching"></section>
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>TEACHING</h5>
                </div>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-2">
                            <pp class='text-left'> Teaching Assistant </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            ECE 5554 / ECE 4554 (Computer Vision), Fall 2018 [<a href="https://filebox.ece.vt.edu/~jbhuang/teaching/ece5554-4554/fa18/index.html">Link</a>] &nbsp;&nbsp; [<a href="Files/Chen_Tutorial_on_Linear_Algebra_and_MATLAB.zip">Tutorial</a>]
                        </pp> </div>
                    </div>
                </div>
                <div class="col-lg-10">
                    <div class="row">
                        <div class="col-sm-2">
                            <pp class='text-left'> Teaching Assistant </pp>
                        </div>
                        <div class="col-sm-10"> <pp class='text-left'>
                            ECE 5424 / CS 5824 (Advanced Machine Learning), Spring 2019 [<a href="https://filebox.ece.vt.edu/~jbhuang/teaching/ECE5424-CS5824/sp19/index.html">Link</a>] [<a href="Files/Lec10.pptx">Lecture on Neural Network</a>]

                        </pp> </div>
                    </div>
                </div>
        </div>
        <br>
        <hr>
    </div> -->

    <section id="misc" name="misc"></section>
    <div class="container desc">
        <div class="row">
                <div class="col-lg-2 col-lg-offset-0">
                    <h5>MISC</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Road Trip</t><br/>
                    I enjoy road-trip as it's a great way to experience local customs.
                    The spectacular landscape reminds me of how great our Creator is.
                    One of my dreams is to visit all the 59 national parks in the US.
                    I have visited 20 national parks already and am looking forward to my next journey.
                    Here is a list of the national parks I've visited <br/> <br/>

                      Arches - Utah <br/>
                      Bryce Canyon - Utah (Favourite!) <br/>
                      Canyonlands - Utah <br/>
                      Capitol Reef - Utah <br/>
                      Crater Lake - Oregon <br/>
                      Everglades - Florida <br/>
                      Grand Canyon - Arizona <br/>
                      Grand Teton - Wyoming <br/>
                      Great Sand Dunes - Colorado <br/>
                      Great Smoky Mountains - North Carolina, Tennessee <br/>
                      Joshua Tree - California <br/>
                      Kings Canyon - California <br/>
                      Mesa Verde - Colorado <br/>
                      Mount Rainier - Washington <br/>
                      North Cascades - Washington <br/>
                      Olympic - Washington <br/>
                      Sequoia - California <br/>
                      Shenandoah - Virginia <br/>
                      Yellowstone - Wyoming, Montana, Idaho <br/>
                      Yosemite - California <br/>
                      Zion - Utah <br/>

                    <p><t>Painting</t><br/>
                    I spent 6 years learning figure sketch, <a href="https://en.wikipedia.org/wiki/Chinese_painting" target="_blank" rel="noopener noreferrer">traditional Chinese painting</a>, and <a href="https://en.wikipedia.org/wiki/Gongbi" target="_blank" rel="noopener noreferrer">Gongbi</a>, specialized in <a href="https://en.wikipedia.org/wiki/Bird-and-flower_painting" target="_blank" rel="noopener noreferrer">Bird-and-flower painting</a>.
                    Through painting, I find inner peace.
                    These days I enjoy drawing some anime characters for fun. Check <a href="Art.html" target="_blank" rel="noopener noreferrer">them</a> out.<br/>

                    <p><t>Activities</t><br/>
                    I regularly engage in hiking, paddleboarding, and snowboarding. If you're in Seattle and enjoy outdoor activities, feel free to contact me. <br/>

                    <p><t>Big fan of Rubik's Cube</t><br/>
                    4x4x4 <br/>
                    5x5x5 <br/>

                    <p><t>Games</t><br/>
                  	I'll call the following games Masterpiece because they change my perspective somehow. <br/> <br/>
                      AIR - VisualArt's <br/>
                      Portal - Valve <br/>
                      To the moon - Freebird Games <br/>

                    <p><t>Music</t><br/>
                  	Just hit any of these songs and let it play ... <br/> <br/>
                      The Police - <a href="https://www.youtube.com/watch?v=OMOGaugKpzs&ab_channel=ThePoliceVEVO" target="_blank" rel="noopener noreferrer">Every Breath You Take</a> <br/>
                      Radiohead - <a href="https://www.youtube.com/watch?v=u5CVsCnxyXg&ab_channel=Radiohead" target="_blank" rel="noopener noreferrer">No Surprises</a> <br/>
                      Radiohead - <a href="https://www.youtube.com/watch?v=t_ENqnpHvD8&ab_channel=TheOrlandometal" target="_blank" rel="noopener noreferrer">Creep (Korn Cover)</a> <br/>
                      Coldplay - <a href="https://www.youtube.com/watch?v=k4V3Mo61fJM&ab_channel=Coldplay" target="_blank" rel="noopener noreferrer">Fix You</a> <br/>
                      宋冬野 - <a href="https://www.youtube.com/watch?v=FiJHoPrS4Y4&ab_channel=%E9%84%92%E5%85%81%E6%9D%B0Gariber" target="_blank" rel="noopener noreferrer">莉莉安</a> <br/>
                      李志 - <a href="https://www.youtube.com/watch?v=K2QE-FRAP0o&ab_channel=%E6%9D%8E%E5%BF%97Lizhi" target="_blank" rel="noopener noreferrer">热河路</a> <br/>

                    <p><t>The Mighty</t><br/>
                    Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you, casting all your anxieties on him, because he cares for you.<br/>
                    <p align="right">1 Peter 5: 6-7</p>

                </div>
        </div><!--/.row -->
        <br>
        <!-- <hr> -->
    </div><!--/.container -->

<!--
    <section id="links" name="misc"></section>
    <div class="container desc">
        <div class="row">
          <div class="col-lg-2 col-lg-offset-0">
                    <h5>Links</h5>
                </div>
                <div class="col-lg-10">
                    <a href="https://github.com/vt-vl-lab/reading_group">Reading Group</a><br/>
                    <a href="https://github.com/vt-vl-lab/cluster">Cluster</a><br/>
                    <a href="http://people.csail.mit.edu/billf/publications/How_To_Do_Research.pdf">How to do research (Bill Freeman)</a><br/>
                </div>
        </div>
        <br>
    </div> -->


    <section id="contact" name="contact"></section>
    <!--FOOTER DESCRIPTION -->
    <div id="footwrap">
        <div class="container">
            <div class="row">

                <div class="col-lg-2 col-lg-offset-0">
                    <h5>CONTACT</h5>
                </div>
                <div class="col-lg-10">
                    <p><t>Email</t><br/>
                        gaochen@meta.com <br/>
                    </p>
                    </p>
                </div>
                <div class="col-lg-2 col-lg-offset-0">
                    <p><sm>SOCIAL LINKS</sm></p>
                    <p>
                        <a href="https://www.facebook.com/ChenGao315"><i class="icon-facebook"></i></a>
                        <a href="https://www.linkedin.com/in/chen-gao-729649a0/"><i class="icon-linkedin"></i></a>
                        <a href="https://twitter.com/gaochen315"><i class="icon-twitter"></i></a>
                    </p>
                    <p>
                        <a href="http://www.easycounter.com/"><img alt="HTML Counter" src="http://www.easycounter.com/counter.php?gaochen315" border="0"></a>
                    </p>
                </div>
            </div><!--/.row -->
        </div><!--/.container -->
    </div><!--/ #footer -->

     <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.js"></script>
  </body>
</html>
