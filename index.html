<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Basic -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Chen Gao | Research Scientist</title>
  <meta name="description" content="Chen Gao is a Research Scientist at Meta working on immersive 3D and 4D experiences, with a focus on dynamic view synthesis and high-fidelity 3D scene representation.">
  <meta name="author" content="Chen Gao">

  <!-- Favicon -->
  <link rel="icon" href="assets/ico/favicon.png" type="image/png">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&family=Raleway:wght@300;400;700&display=swap" rel="stylesheet">

  <!-- CSS -->
  <link href="assets/css/bootstrap.css" rel="stylesheet">
  <link href="assets/css/font-awesome.min.css" rel="stylesheet">
  <link href="assets/css/main.css" rel="stylesheet">

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-S2E6XQJ50R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-S2E6XQJ50R');
  </script>
  <!-- Legacy support for very old browsers -->
  <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <script src="assets/js/respond.min.js"></script>
  <![endif]-->
</head>

  <body data-spy="scroll" data-offset="70" data-target="#nav">

    <nav id="section-topbar">
        <div id="topbar-inner">
            <div class="container">
                <div class="row">
                    <div class="dropdown">
                        <ul id="nav" class="nav">
                            <li class="hidden"><a class="page-scroll" href="#page-top"></a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#about" title="About">About</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#news"  title="News">News</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#paper" title="Paper">Publications</a></li>
                            <li class="menu-item"><a class="page-scroll" href="index.html#misc"  title="Misc">Misc</a></li>
                            <li class="menu-item"><a class="page-scroll" href="Art.html"  title="Blog">Art</a></li>
                        </ul><!--/ uL#nav -->
                    </div><!-- /.dropdown -->

                    <div class="clear"></div>
                </div><!--/.row -->
            </div><!--/.container -->

            <div class="clear"></div>
        </div>
    </nav>

    <header id="headerwrap">
      <div class="container">
        <div class="row centered">
          <div class="col-lg-12">
            <h1>Chen Gao | 髙諶</h1>
            <h3>Research Scientist at Meta Reality Labs</h3><br/><br/>
            <h4><b>Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you, casting all your anxieties on him, because he cares for you. </b></h4>
            <h4><b>1 Peter 5: 6-7</b></h4>
          </div>
        </div>
      </div>
    </header>

    <section id="about">
      <div id="intro">
        <div class="container">

        <div class="row">

          <!-- Avatar -->
          <div class="col-lg-3 col-md-4">
            <img class="img-responsive about-avatar" src="assets/img/chengao.jpg" alt="">
          </div>

          <!-- Text -->
          <div class="col-lg-9 col-md-8">
            <p>
              I am a research scientist at Meta, working on immersive 3D and 4D experiences. My research focuses on dynamic view synthesis and high-fidelity 3D scene representation.
            </p>

            <p>
              I received my Ph.D. from Virginia Tech in 2022, advised by
              <a href="https://filebox.ece.vt.edu/~jbhuang/">Jia-Bin Huang</a>.
              Prior to that, I was a Master's student at the University of Michigan.
              I received my Bachelor's degree from Oregon State University.
            </p>

            <p class="about-links">
              <a href="mailto:gaochen@meta.com">Email</a> &nbsp;/&nbsp;
              <a href="Files/CV_ChenGao.pdf">CV</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=xRsWVc4AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
              <a href="https://twitter.com/gaochen315">Twitter</a> &nbsp;/&nbsp;
              <a href="https://github.com/gaochen315">Github</a>
            </p>
          </div>

        </div>
      </div>
    </section>


    <section id="news" class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>NEWS</h5>
        </div>

        <div class="col-lg-10">
          <div class="news-list">

            <div class="news-row">
              <div class="news-tag">
                <span class="tag-paper">[2025/02]</span>
              </div>
              <div class="news-text">
                Our paper on textured Gaussians is accepted to CVPR 2025.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <span class="tag-code">[2023/06]</span>
              </div>
              <div class="news-text">
                The <a href="https://github.com/facebookresearch/localrf">code</a> of our CVPR 2023 local RF paper is released.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <span class="tag-code">[2023/06]</span>
              </div>
              <div class="news-text">
                The <a href="https://github.com/facebookresearch/robust-dynrf">code</a> of our CVPR 2023 robust DynRF paper is released.
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <span class="tag-activity">[2022/05]</span>
              </div>
              <div class="news-text">
                I passed my PhD defense today!
              </div>
            </div>

            <div class="news-row">
              <div class="news-tag">
                <span class="tag-intern">[2022/03]</span>
              </div>
              <div class="news-text">
                I will be joining Meta as a research scientist.
              </div>
            </div>

          </div>
        </div>
      </div>
      <hr>
    </section>



    <section id="paper" class="container desc">

      <div class="row">
        <div class="col-lg-12">
          <h5>PUBLICATION</h5>
        </div>
      </div>

      <div class="row">
        <div class="col-lg-12">

          <!-- Textured Gaussians -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://www.qinboli.com/images/content/texturedGS.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Textured Gaussians for Enhanced 3D Scene Appearance Modeling
                </span>
              </p>
              <p class="pub-authors">
                Brian Chao, Hung-Yu Tseng, Lorenzo Porzi, <b>Chen Gao</b>, Tuotuo Li,
                Qinbo Li, Ayush Saraf, Jia-Bin Huang, Johannes Kopf,
                Gordon Wetzstein, Changil Kim
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2025</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2411.18625" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://textured-gaussians.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Reflection-Aware NeRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://ra-nerf.github.io/supp/results/Ours/composite/game_room_composite.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Reflection-Aware Neural Radiance Fields
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yipeng Wang, Changil Kim,
                Jia-Bin Huang, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i><b>SIGGRAPH Asia 2024</b> (Conference track)</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2411.04984" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://ra-nerf.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Ambient Gaussian -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://ambientgaussian.github.io/siggraph2024/more_results/IMG_0017/merge-wo-reconstruction.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Modeling Ambient Scene Dynamics for Free-view Synthesis
                </span>
              </p>
              <p class="pub-authors">
                Meng-Li Shih, Jia-Bin Huang, Changil Kim,
                Rajvi Shah, Johannes Kopf, <b>Chen Gao</b>
              </p>
              <p class="pub-venue">
                <i><b>SIGGRAPH 2024</b> (Conference track)</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2406.09395" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://ambientgaussian.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- SpecNeRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="https://limacv.github.io/SpecNeRF_web/images/teaser.jpg" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  SpecNeRF: Gaussian Directional Encoding for Specular Reflections
                </span>
              </p>
              <p class="pub-authors">
                Li Ma, Vasu Agrawal, Haithem Turki, Changil Kim,
                <b>Chen Gao</b>, Pedro V. Sander,
                Michael Zollhöfer, Christian Richardt
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2024</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2312.13102" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://limacv.github.io/SpecNeRF_web/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- OmnimatteRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://omnimatte-rf.github.io/demo/demo4.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  OmnimatteRF: Robust Omnimatte with 3D Background Modeling
                </span>
              </p>
              <p class="pub-authors">
                Geng Lin, <b>Chen Gao</b>, Jia-Bin Huang,
                Changil Kim, Yipeng Wang, Matthias Zwicker, Ayush Saraf
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE International Conference on Computer Vision <b>(ICCV) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2309.07749.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://omnimatte-rf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/OmnimatteRF" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- LocalRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://localrf.github.io/videos/forest1_ours.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Progressively Optimized Local Radiance Fields for Robust View Synthesis
                </span>
              </p>
              <p class="pub-authors">
                Andreas Meuleman, Yu-Lun Liu, <b>Chen Gao</b>,
                Jia-Bin Huang, Changil Kim, Min H. Kim, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://localrf.github.io/localrf.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://localrf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/localrf" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Robust Dynamic Radiance Fields -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://robust-dynrf.github.io/static/videos/outputvideo.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Robust Dynamic Radiance Fields
                </span>
              </p>
              <p class="pub-authors">
                Yu-Lun Liu, <b>Chen Gao</b>, Andreas Meuleman,
                Hung-Yu Tseng, Ayush Saraf, Changil Kim,
                Yung-Yu Chuang, Johannes Kopf, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR) 2023</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2301.02239.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://robust-dynrf.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/facebookresearch/robust-dynrf" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Dynamic View Synthesis -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://filebox.ece.vt.edu/~chengao/free-view-video/teaser.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Dynamic View Synthesis from Dynamic Monocular Video
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Ayush Saraf, Johannes Kopf, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE International Conference on Computer Vision <b>(ICCV) 2021</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2105.06468.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://free-view-video.github.io/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/DynamicNeRF" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Portrait NeRF -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="assets/img/pnerf.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Portrait Neural Radiance Fields from a Single Image
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yichang Shih, Wei-Sheng Lai,
                Chia-Kai Liang, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>arXiv preprint</i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2012.05903.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://portrait-nerf.github.io/" target="_blank">Project page</a>]
              </p>
            </div>
          </div>

          <!-- Flow-edge Guided Video Completion -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="https://gaochen315.github.io/FGVC/ECCV2020/teaser.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Flow-edge Guided Video Completion
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Ayush Saraf, Jia-Bin Huang, Johannes Kopf
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2009.01835.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/FGVC/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/FGVC" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- DRG -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <video class="img-responsive" muted controls autoplay loop>
                <source src="assets/img/DRG.mp4" type="video/mp4">
              </video>
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  DRG: Dual Relation Graph for Human-Object Interaction Detection
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Jiarui Xu, Yuliang Zou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2008.11714.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="http://chengao.vision/DRG/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/DRG" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- NAS-DIP -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/NAS-DIP.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  NAS-DIP: Learning Deep Image Prior with Neural Architecture Search
                </span>
              </p>
              <p class="pub-authors">
                Yun-Chun Chen*, <b>Chen Gao*</b>, Esther Robb, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of European Conference on Computer Vision <b>(ECCV) 2020</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/pdf/2008.11713.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://yunchunchen.github.io/NAS-DIP/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/YunChunChen/NAS-DIP-pytorch" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- SDN -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/SDN.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition
                </span>
              </p>
              <p class="pub-authors">
                Jinwoo Choi, <b>Chen Gao</b>, Joseph Messou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of Neural Information Processing Systems <b>(NeurIPS) 2019</b></i>
              </p>
              <p class="pub-links">
                [<a href="http://papers.nips.cc/paper/8372-why-cant-i-dance-in-the-mall-learning-to-mitigate-scene-bias-in-action-recognition.pdf" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="http://chengao.vision/SDN/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/SDN" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- iCAN -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/HOI.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Yuliang Zou, Jia-Bin Huang
              </p>
              <p class="pub-venue">
                <i>Proceedings of The British Machine Vision Conference <b>(BMVC) 2018</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1808.10437" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/iCAN/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/vt-vl-lab/iCAN" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- pRPCA -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/pRPCA.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Panoramic Robust PCA for Foreground-Background Separation on Noisy, Free-Motion Camera Video
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao*</b>, Brian E. Moore*, Raj Rao Nadakuditi
              </p>
              <p class="pub-venue">
                <i>IEEE Transactions on Computational Imaging <b>(TCI) 2019</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1712.06229" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/pRPCA/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/panoramicRPCA" target="_blank">Code</a>]
              </p>
            </div>
          </div>

          <!-- Augmented RPCA -->
          <div class="pub-card row">
            <div class="col-lg-3 pub-media">
              <img class="img-responsive" src="assets/img/RPCA.gif" alt="">
            </div>
            <div class="col-lg-8 pub-content">
              <p class="pub-title">
                <span class="pub-title-text">
                  Augmented Robust PCA For Foreground-Background Separation on Noisy, Moving Camera Video
                </span>
              </p>
              <p class="pub-authors">
                <b>Chen Gao</b>, Brian E. Moore, Raj Rao Nadakuditi
              </p>
              <p class="pub-venue">
                <i>Proceedings of IEEE Global Conference on Signal and Information Processing <b>(GlobalSIP) 2017 (Oral)</b></i>
              </p>
              <p class="pub-links">
                [<a href="https://arxiv.org/abs/1709.09328" target="_blank">Paper (PDF)</a>]
                &nbsp;
                [<a href="https://gaochen315.github.io/pRPCA/" target="_blank">Project page</a>]
                &nbsp;
                [<a href="https://github.com/gaochen315/panoramicRPCA" target="_blank">Code</a>]
              </p>
            </div>
          </div>

        </div>
      </div>

      <hr>
    </section>



    <!--EDUCATION DESCRIPTION -->
    <section id="education" class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>EDUCATION</h5>
        </div>

        <div class="col-lg-10">
          <div class="edu-list">

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/vt.png" alt="">
              <p class="text-center">
                Virginia Tech <br/>
                Doctor of Philosophy
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/umich.png" alt="">
              <p class="text-center">
                University of Michigan <br/>
                Master of Science
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/osu_.png" alt="">
              <p class="text-center">
                Oregon State University <br/>
                Bachelor of Science
              </p>
            </div>

          </div>
        </div>
      </div>
      <hr>
    </section>


    <section class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>INDUSTRY</h5>
        </div>

        <div class="col-lg-10">
          <div class="edu-list">

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/Meta.png" alt="">
              <p class="text-center">
                Research Scientist <br/>
                2022 - Present
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/google.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2021
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/google.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2020
              </p>
            </div>

            <div class="edu-item">
              <img class="img-responsive edu-logo" src="assets/img/facebook.png" alt="">
              <p class="text-center">
                Research Intern <br/>
                Summer 2019
              </p>
            </div>

          </div>
        </div>
      </div>
      <hr>
    </section>


    <section id="misc" class="container desc">
      <div class="row">
        <div class="col-lg-2 col-lg-offset-0">
          <h5>MISC</h5>
        </div>

        <div class="col-lg-10 misc-content">

          <div class="misc-item">
            <p>
              <span class="misc-title">Road Trip</span>
            </p>
            <p>
              I enjoy road-trip as it's a great way to experience local customs.
              The spectacular landscape reminds me of how great our Creator is.
              One of my dreams is to visit all the 59 national parks in the US.
              I have visited 22 national parks already and am looking forward to my next journey.
              Here is a list of the national parks I've visited
            </p>

            <ul class="misc-list">
              <li>Arches - Utah</li>
              <li>Bryce Canyon - Utah (Favourite!)</li>
              <li>Canyonlands - Utah</li>
              <li>Capitol Reef - Utah</li>
              <li>Crater Lake - Oregon</li>
              <li>Everglades - Florida</li>
              <li>Glacier National Park - Montana</li>
              <li>Grand Canyon - Arizona</li>
              <li>Grand Teton - Wyoming</li>
              <li>Great Sand Dunes - Colorado</li>
              <li>Great Smoky Mountains - North Carolina, Tennessee</li>
              <li>Joshua Tree - California</li>
              <li>Kings Canyon - California</li>
              <li>Mesa Verde - Colorado</li>
              <li>Mount Rainier - Washington</li>
              <li>North Cascades - Washington</li>
              <li>Olympic - Washington</li>
              <li>Sequoia - California</li>
              <li>Shenandoah - Virginia</li>
              <li>Yellowstone - Wyoming, Montana, Idaho</li>
              <li>Yosemite - California</li>
              <li>Zion - Utah</li>
            </ul>
          </div>

          <div class="misc-item">
            <p>
              <span class="misc-title">Painting</span>
            </p>
            <p>
              I spent 6 years learning figure sketch,
              <a href="https://en.wikipedia.org/wiki/Chinese_painting" target="_blank" rel="noopener noreferrer">
                traditional Chinese painting
              </a>,
              and
              <a href="https://en.wikipedia.org/wiki/Gongbi" target="_blank" rel="noopener noreferrer">
                Gongbi
              </a>,
              specialized in
              <a href="https://en.wikipedia.org/wiki/Bird-and-flower_painting" target="_blank" rel="noopener noreferrer">
                Bird-and-flower painting
              </a>.
              Through painting, I find inner peace.
              These days I enjoy drawing some anime characters for fun.
              Check
              <a href="Art.html" target="_blank" rel="noopener noreferrer">them</a>
              out.
            </p>
          </div>

          <div class="misc-item">
            <p>
              <span class="misc-title">Activities</span>
            </p>
            <p>
              I regularly engage in hiking, paddleboarding, and snowboarding.
              If you're in Seattle and enjoy outdoor activities, feel free to contact me.
            </p>
          </div>

          <div class="misc-item">
            <p>
              <span class="misc-title">Big fan of Rubik's Cube</span>
            </p>
            <p>
              4x4x4 <br/>
              5x5x5
            </p>
          </div>

          <div class="misc-item">
            <p>
              <span class="misc-title">Games</span>
            </p>
            <p>
              I'll call the following games Masterpiece because they change my perspective somehow.
            </p>
            <ul class="misc-list">
              <li>AIR - VisualArt's</li>
              <li>Portal - Valve</li>
              <li>To the moon - Freebird Games</li>
            </ul>
          </div>
          <!-- <div class="misc-item">
            <p><t>Music</t></p>
            <ul class="misc-list">
              <li>The Police - <a href="https://www.youtube.com/watch?v=OMOGaugKpzs&ab_channel=ThePoliceVEVO" target="_blank" rel="noopener noreferrer">Every Breath You Take</a></li>
              <li>Radiohead - <a href="https://www.youtube.com/watch?v=u5CVsCnxyXg&ab_channel=Radiohead" target="_blank" rel="noopener noreferrer">No Surprises</a></li>
              <li>Radiohead - <a href="https://www.youtube.com/watch?v=t_ENqnpHvD8&ab_channel=TheOrlandometal" target="_blank" rel="noopener noreferrer">Creep (Korn Cover)</a></li>
              <li>Coldplay - <a href="https://www.youtube.com/watch?v=k4V3Mo61fJM&ab_channel=Coldplay" target="_blank" rel="noopener noreferrer">Fix You</a></li>
              <li>宋冬野 - <a href="https://www.youtube.com/watch?v=FiJHoPrS4Y4&ab_channel=%E9%84%92%E5%85%81%E6%9D%B0Gariber" target="_blank" rel="noopener noreferrer">莉莉安</a></li>
              <li>李志 - <a href="https://www.youtube.com/watch?v=K2QE-FRAP0o&ab_channel=%E6%9D%8E%E5%BF%97Lizhi" target="_blank" rel="noopener noreferrer">热河路</a></li>
            </ul>
          </div> -->
          <div class="misc-item">
            <p>
              <span class="misc-title">The Mighty</span>
            </p>
            <p>
              Humble yourselves, therefore, under the mighty hand of God so that at the proper time he may exalt you,
              casting all your anxieties on him, because he cares for you.
            </p>
            <p style="text-align:right;">
              1 Peter 5: 6-7
            </p>
          </div>

        </div>
      </div>
    </section>



    <footer id="contact">
      <div id="footwrap">
      <div class="container">
        <div class="row">

          <div class="col-lg-2 col-lg-offset-0">
            <h5>CONTACT</h5>
          </div>

          <div class="col-lg-5">
            <p>
              <b>Email</b><br/>
              gaochen@meta.com
            </p>
          </div>

          <div class="col-lg-3 col-lg-offset-2">
            <p><span class="footer-label">SOCIAL LINKS</span></p>
            <p class="footer-social">
              <a href="https://www.facebook.com/ChenGao315"><i class="icon-facebook"></i></a>
              <a href="https://www.linkedin.com/in/chen-gao-729649a0/"><i class="icon-linkedin"></i></a>
              <a href="https://twitter.com/gaochen315"><i class="icon-twitter"></i></a>
            </p>
            <p class="footer-counter">
              <a href="http://www.easycounter.com/">
                <img alt="HTML Counter" src="http://www.easycounter.com/counter.php?gaochen315" border="0">
              </a>
            </p>
          </div>

        </div>
      </div>
    </footer>


     <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.js"></script>
  </body>
</html>
